# Neural-Machine-Translation
NLP Application Project


2.2.3 Build an NMT (Neural MT) system when training data (parallel sentences in the concerned source and target language) is available in a domain. However, such domain data is of small size. Machine learning is to be used in such a way that the small sized domain data can be combined with the large amount of general data.

Contributor:
1) Arushi Singhal 201516178
2) Simran Singhal 201516190

Report:- https://docs.google.com/document/d/1n1o2qPxLaCnB0E83i_ZiPZCA_8fN_uMCrQ-CQCzlql4/edit?usp=sharing

# References
1) https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html (main)
2) https://arxiv.org/abs/1409.3215 (Research Paper)
3) http://www.manythings.org/anki/
4) https://machinelearningmastery.com/encoder-decoder-recurrent-neural-network-models-neural-machine-translation/
5) https://machinelearningmastery.com/encoder-decoder-long-short-term-memory-networks/
6) https://machinelearningmastery.com/develop-neural-machine-translation-system-keras/
7) http://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/
8) https://towardsdatascience.com/nlp-sequence-to-sequence-networks-part-1-processing-text-data-d141a5643b72
9) https://towardsdatascience.com/nlp-sequence-to-sequence-networks-part-2-seq2seq-model-encoderdecoder-model-6c22e29fd7e1
10) https://nlp.stanford.edu/~johnhew/public/14-seq2seq.pdf
11) https://www.analyticsvidhya.com/blog/2018/03/essentials-of-deep-learning-sequence-to-sequence-modelling-with-attention-part-i/
12) https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html
13) https://www.coursera.org/learn/nlp-sequence-models/lecture/ftkzt/recurrent-neural-network-model
14) https://machinelearningmastery.com/encoder-decoder-attention-sequence-to-sequence-prediction-keras/ (important)
15) https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html
16) https://github.com/bentrevett/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb

# Hindi text Normalization

1) http://talukdar.net/papers/KBCS04_HPL-1.pdf
2) https://medium.com/lingvo-masino/do-you-know-about-text-normalization-a19fe3090694

# The IIT Bombay English-Hindi Parallel Corpus
https://www.cse.iitb.ac.in/~pb/papers/lrec18-iitbparallel.pdf

# Dataset Link
http://10.3.1.91/~datashare/wat/

# Document Link to the Errors found in the Dataset
https://docs.google.com/document/d/1zz67TTlVi0YuH7zUjD3up4O_7qKd8lCtElhxcH1bMWk/edit

# Data Generator
https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly
